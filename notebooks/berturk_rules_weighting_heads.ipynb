{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0942f980-d4c2-4fcc-99a0-737b8bf88c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6db2e9a0-1d86-4eab-bd90-469707ffc1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=False, nb_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1111f-49ac-4cd1-85ab-318455fc96d2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b215f85c-0ede-47b2-929f-e61be14809e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_converters = {'sentences': pd.eval, \"special_pattern\": pd.eval, \"anti_hs\": pd.eval, \"hs_specific_verb\": pd.eval, \"adj_bef_keyword\": pd.eval, \"adj_after_keyword\": pd.eval}\n",
    "data = pd.read_csv(\"../../data/data_cleaned_sentences_phases_rules.csv\", sep='|', converters=list_converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e285dd78-b54b-473d-ab7f-81abdece7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title\"] = data[\"title\"].parallel_apply(lambda title: title if isinstance(title, str) else \"\") \n",
    "data[\"text\"] = data.parallel_apply(lambda row: \" \".join([sent for sent in [row[\"title\"]] + row[\"sentences\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46bccf6-4239-411e-a588-dca8961c3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haber\n",
      "['filistinde yahudi yerleşimcilerin polis korumasında mescidi aksanın avlusuna girmesi gerginliğe neden oldu', 'yahudi yerleşimcilerden oluşan kişilik grup israil polisinin koruması altında mescidi aksanın avlusuna girdi', 'bunun üzerine birgrup filistinli gönüllü kadın yahudi yerleşimcilere tepki göstererek oturma eylemi düzenledi israilli kolluk güçleri olayı protesto eden filistinlilere gerçek mermilerle saldırdı', 'filistinlilerden gerçek ise plastik mermilerle yaralanırken onlanca kişi ise atılan göz yaşartıcı gazdan etkilendi', 'israil polisinin dün sabah saatlerinden itibaren aksanın kapılarında güvenlik önlemlerini arttırdığı ifade edildi', 'öte yandan dün israil gazzede hamasm silahlı kanadı izzeddin elkassam tugayiarının eğitim alanına hava saldırısı düzenledi', 'saldırıda ölen ya da yaralanan olmadı', 'imi lifi mm buj']\n",
      "--------------------\n",
      "haber filistinde yahudi yerleşimcilerin polis korumasında mescidi aksanın avlusuna girmesi gerginliğe neden oldu yahudi yerleşimcilerden oluşan kişilik grup israil polisinin koruması altında mescidi aksanın avlusuna girdi bunun üzerine birgrup filistinli gönüllü kadın yahudi yerleşimcilere tepki göstererek oturma eylemi düzenledi israilli kolluk güçleri olayı protesto eden filistinlilere gerçek mermilerle saldırdı filistinlilerden gerçek ise plastik mermilerle yaralanırken onlanca kişi ise atılan göz yaşartıcı gazdan etkilendi israil polisinin dün sabah saatlerinden itibaren aksanın kapılarında güvenlik önlemlerini arttırdığı ifade edildi öte yandan dün israil gazzede hamasm silahlı kanadı izzeddin elkassam tugayiarının eğitim alanına hava saldırısı düzenledi saldırıda ölen ya da yaralanan olmadı imi lifi mm buj\n",
      "hate\n"
     ]
    }
   ],
   "source": [
    "row = data.loc[19]\n",
    "print(row.title)\n",
    "print(row.sentences)\n",
    "print(\"--------------------\")\n",
    "print(row.text)\n",
    "print(row.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be644a2-1253-4f6a-96ca-6d099b1ca755",
   "metadata": {},
   "source": [
    "## Huggingface custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb812e76-453a-47b8-95f3-d27fb4631f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"all_rules\"] = data.apply(lambda row: np.array(row[\"special_pattern\"] + [row[\"general_rule\"]] + row[\"anti_hs\"] + row[\"hs_specific_verb\"] + row[\"adj_bef_keyword\"] + row[\"adj_after_keyword\"]).astype(np.float32), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f56d8f1-fe21-44ce-af84-01a1720ae75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0, \"all_rules\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cf8e2f-c6ff-4d12-9164-ed5dcd5c3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arute/miniconda3/envs/nlp_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04afaee0-c305-4900-b852-6c101eb53c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDVDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, idxs, all_rules):\n",
    "        self.label_encodings = {\"not_hate\": 0, \"hate\": 1}\n",
    "        self.rev_label_encodings = {0: \"not_hate\", 1: \"hate\"}\n",
    "        self.encodings = encodings\n",
    "        self.labels = [self.label_encodings[label] for label in labels]\n",
    "        self.idxs = idxs\n",
    "        self.rules = all_rules\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['rules'] = torch.tensor(self.rules[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783e8a91-bfe4-422d-a0fd-d09716071898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")\n",
    "dataset_dict = {}\n",
    "for phase in [\"train\", \"val\", \"test\"]:\n",
    "    idxs = list(data.loc[data[\"phase\"] == phase, \"id\"].values)\n",
    "    texts = list(data.loc[data[\"phase\"] == phase, \"text\"].values)\n",
    "    labels = list(data.loc[data[\"phase\"] == phase, \"Label\"].values)\n",
    "    all_rules = list(data.loc[data[\"phase\"] == phase, \"all_rules\"].values)\n",
    "    \n",
    "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "    dataset = HDVDataset(encodings, labels, idxs, all_rules)\n",
    "    dataset_dict[phase] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9985b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dist: Counter({1: 10074, 0: 9944})\n",
      "Validation dist: Counter({1: 1257, 0: 1243})\n",
      "Test dist: Counter({1: 1255, 0: 1242})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dist: {Counter(dataset_dict['train'].labels)}\")\n",
    "print(f\"Validation dist: {Counter(dataset_dict['val'].labels)}\")\n",
    "print(f\"Test dist: {Counter(dataset_dict['test'].labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c599074-ae92-44fb-8af5-fe40c98255f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99600c4f-63ba-490e-a4bc-4824caeb784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = load_metric(\"precision\")\n",
    "rec = load_metric(\"recall\")\n",
    "acc = load_metric(\"accuracy\")\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    result = {}\n",
    "    for mtrc in [prec, rec, acc, f1]:\n",
    "        mtrc_result = mtrc.compute(predictions=predictions, references=labels)\n",
    "        result.update(mtrc_result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b0cc9-5464-4f6e-9350-9762310187cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Huggingface models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd0984af-9c14-4c48-8b20-975fb81d8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c35ae11-4894-41b0-ae56-871fc264e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_epochs = 2\n",
    "batch_size = 4\n",
    "checkpoint = \"dbmdz/bert-base-turkish-128k-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d9fba1-cc80-4d54-9fcc-2a484dccfb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../experiments_berturk_weighted_drop015/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1526938-7474-402a-9088-85f360d7f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSRuleModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels, rule_dimension=None): \n",
    "        super(HSRuleModel, self).__init__() \n",
    "        self.num_labels = num_labels\n",
    "        self.rule_dimension = rule_dimension\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        #Load Model with given checkpoint and extract its body\n",
    "        self.model = AutoModel.from_pretrained(checkpoint, config=AutoConfig.from_pretrained(checkpoint, output_attentions=True, output_hidden_states=True))\n",
    "        self.dropout1 = nn.Dropout(0.2, inplace=False) \n",
    "        self.classifier1 = nn.Linear(768, 128) # load and initialize weights\n",
    "        self.dropout2 = nn.Dropout(0.2, inplace=False) \n",
    "        self.classifier2 = nn.Linear(128, 2) # load and initialize weights\n",
    "        \n",
    "        #self.weighter1 = nn.Linear(768 * 8, 768 * 2)\n",
    "        #self.w_dropout1 = nn.Dropout(0.2, inplace=False) \n",
    "        self.weighter2 = nn.Linear(768 * 2, 2)\n",
    "        self.w_dropout2 = nn.Dropout(0.2, inplace=False) \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None, labels=None, rules=None):\n",
    "        #Extract outputs from the body\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        sequence_output = self.dropout1(outputs[0]) #outputs[0]=last hidden state\n",
    "        #sequence_output = sequence_output[:, 0, :].view(-1, 768)\n",
    "        sequence_output = sequence_output[:, :2, :]\n",
    "        weights = self.weighter2(sequence_output.contiguous().view(sequence_output.shape[0], -1))\n",
    "        weights = self.w_dropout2(self.relu(weights))\n",
    "        #weights = self.weighter2(weights)\n",
    "        #weights = self.w_dropout2(self.relu(weights))\n",
    "        weights = torch.unsqueeze(self.softmax(weights), dim=2)\n",
    "        \n",
    "        sequence_output = torch.mean(sequence_output * weights, dim=1)\n",
    "        sequence_output = torch.squeeze(sequence_output, 1)\n",
    "        \n",
    "        #output_with_rules = torch.cat((sequence_output, rules), dim=1)\n",
    "        output = self.relu(self.classifier1(sequence_output)) # calculate losses\n",
    "        output = self.dropout2(output)\n",
    "        #output = torch.cat((output, rules), dim=1)\n",
    "        logits = self.classifier2(output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34495ed-53b7-4e9b-826d-3dd0a415c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_dict[\"train\"], batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_dict[\"val\"], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5380a43-47d5-42e6-aa80-0af4bcc16de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = HSRuleModel(checkpoint, num_labels=2, rule_dimension=26).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-05)\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'max', patience=2, min_lr=1e-09, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f97e96f8-5477-4fba-924a-53796a3576bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch   step        F1 Accuracy Precision    Recall\n",
       "0   0.0  500.0  0.872878   0.8652  0.829986  0.920446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5   0.0  3000.0  0.905997   0.9072  0.923204  0.889419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5   0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6   0.0  3500.0  0.887819   0.8788  0.830332  0.953858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5   0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6   0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7   0.0  4000.0  0.913249    0.912  0.905395  0.921241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5   0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6   0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7   0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8   0.0  4500.0  0.907995   0.9084  0.917208  0.898966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch    step        F1 Accuracy Precision    Recall\n",
       "0   0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1   0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2   0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3   0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4   0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5   0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6   0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7   0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8   0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9   0.0  5000.0  0.915493   0.9136  0.900693  0.930788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041\n",
       "15   1.0  3000.0  0.918728   0.9172  0.906977  0.930788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.898036</td>\n",
       "      <td>0.945903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041\n",
       "15   1.0  3000.0  0.918728   0.9172  0.906977  0.930788\n",
       "16   1.0  3500.0  0.921348   0.9188  0.898036  0.945903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.898036</td>\n",
       "      <td>0.945903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.92099</td>\n",
       "      <td>0.918059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041\n",
       "15   1.0  3000.0  0.918728   0.9172  0.906977  0.930788\n",
       "16   1.0  3500.0  0.921348   0.9188  0.898036  0.945903\n",
       "17   1.0  4000.0  0.919522   0.9192   0.92099  0.918059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.898036</td>\n",
       "      <td>0.945903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.92099</td>\n",
       "      <td>0.918059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.918577</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.912804</td>\n",
       "      <td>0.924423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041\n",
       "15   1.0  3000.0  0.918728   0.9172  0.906977  0.930788\n",
       "16   1.0  3500.0  0.921348   0.9188  0.898036  0.945903\n",
       "17   1.0  4000.0  0.919522   0.9192   0.92099  0.918059\n",
       "18   1.0  4500.0  0.918577   0.9176  0.912804  0.924423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3971315/2019920556.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metric_df = metric_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.872878</td>\n",
       "      <td>0.8652</td>\n",
       "      <td>0.829986</td>\n",
       "      <td>0.920446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.884226</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864766</td>\n",
       "      <td>0.94113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.903715</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.94829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.905997</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.889419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.887819</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.830332</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913249</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905395</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.898966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.900693</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.894936</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.916019</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.878944</td>\n",
       "      <td>0.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.910329</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.957041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.898036</td>\n",
       "      <td>0.945903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.92099</td>\n",
       "      <td>0.918059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.918577</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.912804</td>\n",
       "      <td>0.924423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.919657</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.902066</td>\n",
       "      <td>0.937947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.872878   0.8652  0.829986  0.920446\n",
       "1    0.0  1000.0  0.884226   0.8764  0.835694  0.938743\n",
       "2    0.0  1500.0  0.899297   0.8968  0.882759  0.916468\n",
       "3    0.0  2000.0  0.901333   0.8964  0.864766   0.94113\n",
       "4    0.0  2500.0  0.903715   0.8984  0.863143   0.94829\n",
       "5    0.0  3000.0  0.905997   0.9072  0.923204  0.889419\n",
       "6    0.0  3500.0  0.887819   0.8788  0.830332  0.953858\n",
       "7    0.0  4000.0  0.913249    0.912  0.905395  0.921241\n",
       "8    0.0  4500.0  0.907995   0.9084  0.917208  0.898966\n",
       "9    0.0  5000.0  0.915493   0.9136  0.900693  0.930788\n",
       "10   1.0   500.0  0.917829   0.9152  0.894936  0.941925\n",
       "11   1.0  1000.0  0.916019   0.9136  0.895817  0.937152\n",
       "12   1.0  1500.0  0.918748    0.918  0.915482  0.922037\n",
       "13   1.0  2000.0  0.914504   0.9104  0.878944  0.953063\n",
       "14   1.0  2500.0  0.910329   0.9052  0.867965  0.957041\n",
       "15   1.0  3000.0  0.918728   0.9172  0.906977  0.930788\n",
       "16   1.0  3500.0  0.921348   0.9188  0.898036  0.945903\n",
       "17   1.0  4000.0  0.919522   0.9192   0.92099  0.918059\n",
       "18   1.0  4500.0  0.918577   0.9176  0.912804  0.924423\n",
       "19   1.0  5000.0  0.919657   0.9176  0.902066  0.937947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: reducing learning rate of group 0 to 2.5000e-06.\n"
     ]
    }
   ],
   "source": [
    "metric_df = pd.DataFrame(columns=[\"epoch\", \"step\", \"F1\", \"Accuracy\", \"Precision\", \"Recall\"])\n",
    "\n",
    "best_val_f1 = 0.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 500 == 0 and i != 0:\n",
    "            os.makedirs(results_path, exist_ok=True)\n",
    "            #torch.save({\n",
    "            #        'epoch': epoch,\n",
    "            #        'steps': i,\n",
    "            #        'model_state_dict': model.state_dict(),\n",
    "            #        'optimizer_state_dict': optimizer.state_dict()\n",
    "            #    }, \n",
    "            #    os.path.join(results_path, f\"steps_{i}.pth\")\n",
    "            #)\n",
    "\n",
    "            model.eval()\n",
    "            for batch in val_loader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch)\n",
    "\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                rec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                prec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "                \n",
    "            model.train()\n",
    "            \n",
    "            step_f1_score = f1.compute()['f1']\n",
    "            metric_df = metric_df.append({\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": i,\n",
    "                    \"Precision\": prec.compute()['precision'],\n",
    "                    \"Recall\": rec.compute()['recall'],\n",
    "                    \"Accuracy\": acc.compute()['accuracy'],\n",
    "                    \"F1\": step_f1_score\n",
    "                },\n",
    "                ignore_index = True\n",
    "            )\n",
    "            display(metric_df)\n",
    "            if step_f1_score > best_val_f1:\n",
    "                best_val_f1 = step_f1_score\n",
    "                \n",
    "                torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'steps': i,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()\n",
    "                    }, \n",
    "                    os.path.join(results_path, f\"best_model.pth\")\n",
    "                )\n",
    "            lr_scheduler.step(step_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6939b223-5231-44ef-9a20-aebd959382be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.858177</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.786994</td>\n",
       "      <td>0.943516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.868186</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>0.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.868164</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.92922</td>\n",
       "      <td>0.814638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.899765</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.885891</td>\n",
       "      <td>0.914081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.901464</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.89685</td>\n",
       "      <td>0.906126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.910161</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.897833</td>\n",
       "      <td>0.922832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.907989</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.866329</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.906851</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.878449</td>\n",
       "      <td>0.937152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.903202</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.857654</td>\n",
       "      <td>0.953858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.905493</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.891806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.903352</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.906396</td>\n",
       "      <td>0.924423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.916863</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.904099</td>\n",
       "      <td>0.929992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.917563</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.91866</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.906274</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.917712</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.904247</td>\n",
       "      <td>0.931583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.920858</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.902905</td>\n",
       "      <td>0.939539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.918059</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.918059</td>\n",
       "      <td>0.918059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.915186</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.92945</td>\n",
       "      <td>0.901352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.921454</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>0.90553</td>\n",
       "      <td>0.937947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    step        F1 Accuracy Precision    Recall\n",
       "0    0.0   500.0  0.858177   0.8432  0.786994  0.943516\n",
       "1    0.0  1000.0  0.868186   0.8704  0.888426  0.848846\n",
       "2    0.0  1500.0  0.868164   0.8756   0.92922  0.814638\n",
       "3    0.0  2000.0  0.899765   0.8976  0.885891  0.914081\n",
       "4    0.0  2500.0  0.901464   0.9004   0.89685  0.906126\n",
       "5    0.0  3000.0  0.910161   0.9084  0.897833  0.922832\n",
       "6    0.0  3500.0  0.907989   0.9028  0.866329  0.953858\n",
       "7    0.0  4000.0  0.906851   0.9032  0.878449  0.937152\n",
       "8    0.0  4500.0  0.903202   0.8972  0.857654  0.953858\n",
       "9    0.0  5000.0  0.905493   0.9064  0.919606  0.891806\n",
       "10   1.0   500.0  0.912598   0.9112  0.903352  0.922037\n",
       "11   1.0  1000.0  0.915321    0.914  0.906396  0.924423\n",
       "12   1.0  1500.0  0.916863   0.9152  0.904099  0.929992\n",
       "13   1.0  2000.0  0.917563   0.9172   0.91866  0.916468\n",
       "14   1.0  2500.0  0.918367   0.9168  0.906274  0.930788\n",
       "15   1.0  3000.0  0.917712    0.916  0.904247  0.931583\n",
       "16   1.0  3500.0  0.920858   0.9188  0.902905  0.939539\n",
       "17   1.0  4000.0  0.918059   0.9176  0.918059  0.918059\n",
       "18   1.0  4500.0  0.915186    0.916   0.92945  0.901352\n",
       "19   1.0  5000.0  0.921454   0.9196   0.90553  0.937947"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df # drop02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "993cdae0-d6f6-48a5-8ea6-5aeea04f49c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.844279</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.878007</td>\n",
       "      <td>0.813047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.880531</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.820619</td>\n",
       "      <td>0.949881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.901244</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.881369</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.864234</td>\n",
       "      <td>0.941925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.89644</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.911934</td>\n",
       "      <td>0.881464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.908307</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.894981</td>\n",
       "      <td>0.922037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.907225</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.90047</td>\n",
       "      <td>0.914081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.903487</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.921423</td>\n",
       "      <td>0.886237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.89695</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93071</td>\n",
       "      <td>0.865553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.91794</td>\n",
       "      <td>0.907717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.913304</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.917335</td>\n",
       "      <td>0.909308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.918627</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.891467</td>\n",
       "      <td>0.947494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.918375</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.893825</td>\n",
       "      <td>0.944312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.919329</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.923015</td>\n",
       "      <td>0.915672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.915215</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.891403</td>\n",
       "      <td>0.940334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.904708</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.859084</td>\n",
       "      <td>0.955449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.954654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.913392</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.906126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.914668</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.904355</td>\n",
       "      <td>0.925219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.916468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step        F1 Accuracy Precision    Recall\n",
       "0    500.0  0.844279   0.8492  0.878007  0.813047\n",
       "1   1000.0  0.880531   0.8704  0.820619  0.949881\n",
       "2   1500.0  0.901244   0.8984  0.881369  0.922037\n",
       "3   2000.0  0.901408   0.8964  0.864234  0.941925\n",
       "4   2500.0   0.89644   0.8976  0.911934  0.881464\n",
       "5   3000.0  0.908307   0.9064  0.894981  0.922037\n",
       "6   3500.0  0.907225    0.906   0.90047  0.914081\n",
       "7   4000.0  0.903487   0.9048  0.921423  0.886237\n",
       "8   4500.0   0.89695      0.9   0.93071  0.865553\n",
       "9   5000.0    0.9128   0.9128   0.91794  0.907717\n",
       "10   500.0  0.913304   0.9132  0.917335  0.909308\n",
       "11  1000.0  0.918627   0.9156  0.891467  0.947494\n",
       "12  1500.0  0.918375   0.9156  0.893825  0.944312\n",
       "13  2000.0  0.919329   0.9192  0.923015  0.915672\n",
       "14  2500.0  0.915215   0.9124  0.891403  0.940334\n",
       "15  3000.0  0.904708   0.8988  0.859084  0.955449\n",
       "16  3500.0  0.904977   0.8992  0.860215  0.954654\n",
       "17  4000.0  0.913392   0.9136  0.920776  0.906126\n",
       "18  4500.0  0.914668   0.9132  0.904355  0.925219\n",
       "19  5000.0  0.916468    0.916  0.916468  0.916468"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df #.to_csv(os.path.join(results_path, \"try_2_metrics.csv\"), index=False) # try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77ac0da6-e7b6-432c-a048-5504fe71ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.648876</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.551313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.752533</td>\n",
       "      <td>0.827367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.832146</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>0.828211</td>\n",
       "      <td>0.836118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.861423</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.813871</td>\n",
       "      <td>0.914877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.845734</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>0.896613</td>\n",
       "      <td>0.800318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.874606</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.867084</td>\n",
       "      <td>0.882259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.881712</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.862909</td>\n",
       "      <td>0.901352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.900422</td>\n",
       "      <td>0.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.875187</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.931583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.882604</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.860272</td>\n",
       "      <td>0.906126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>0.884491</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.898277</td>\n",
       "      <td>0.871122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.816835</td>\n",
       "      <td>0.964996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.871648</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.791558</td>\n",
       "      <td>0.969769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.898885</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.899602</td>\n",
       "      <td>0.89817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.875789</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.827367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.83698</td>\n",
       "      <td>0.943516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8500.0</td>\n",
       "      <td>0.890865</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.905505</td>\n",
       "      <td>0.876691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.898363</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.938743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9500.0</td>\n",
       "      <td>0.898311</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.850142</td>\n",
       "      <td>0.952267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.898978</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.945107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.905527</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.892581</td>\n",
       "      <td>0.918854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.906491</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.881292</td>\n",
       "      <td>0.933174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11500.0</td>\n",
       "      <td>0.906677</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.890337</td>\n",
       "      <td>0.923628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.90873</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.906572</td>\n",
       "      <td>0.910899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>0.904577</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.882665</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.908028</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.889992</td>\n",
       "      <td>0.92681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13500.0</td>\n",
       "      <td>0.907537</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.886864</td>\n",
       "      <td>0.929196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.908171</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.888804</td>\n",
       "      <td>0.928401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14500.0</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.88872</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.907465</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.887452</td>\n",
       "      <td>0.928401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15500.0</td>\n",
       "      <td>0.907818</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.888128</td>\n",
       "      <td>0.928401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>0.908171</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.888804</td>\n",
       "      <td>0.928401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16500.0</td>\n",
       "      <td>0.908171</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>0.888804</td>\n",
       "      <td>0.928401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.88872</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17500.0</td>\n",
       "      <td>0.907321</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.92681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>0.907321</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.92681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18500.0</td>\n",
       "      <td>0.907321</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.92681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19000.0</td>\n",
       "      <td>0.907321</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.92681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19500.0</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.88872</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.88872</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.907746</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.88872</td>\n",
       "      <td>0.927605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       step        F1 Accuracy Precision    Recall\n",
       "0     500.0  0.648876      0.7  0.788396  0.551313\n",
       "1    1000.0  0.788177   0.7764  0.752533  0.827367\n",
       "2    1500.0  0.832146   0.8304  0.828211  0.836118\n",
       "3    2000.0  0.861423    0.852  0.813871  0.914877\n",
       "4    2500.0  0.845734   0.8532  0.896613  0.800318\n",
       "5    3000.0  0.874606   0.8728  0.867084  0.882259\n",
       "6    3500.0  0.881712   0.8784  0.862909  0.901352\n",
       "7    4000.0  0.873874   0.8768  0.900422  0.848846\n",
       "8    4500.0  0.875187   0.8664  0.825229  0.931583\n",
       "9    5000.0  0.882604   0.8788  0.860272  0.906126\n",
       "10   5500.0  0.884491   0.8856  0.898277  0.871122\n",
       "11   6000.0  0.884756   0.8736  0.816835  0.964996\n",
       "12   6500.0  0.871648   0.8564  0.791558  0.969769\n",
       "13   7000.0  0.898885   0.8984  0.899602   0.89817\n",
       "14   7500.0  0.875789    0.882  0.930233  0.827367\n",
       "15   8000.0  0.887061   0.8792   0.83698  0.943516\n",
       "16   8500.0  0.890865    0.892  0.905505  0.876691\n",
       "17   9000.0  0.898363   0.8932  0.861314  0.938743\n",
       "18   9500.0  0.898311   0.8916  0.850142  0.952267\n",
       "19  10000.0  0.898978   0.8932  0.857143  0.945107\n",
       "20  10500.0  0.905527   0.9036  0.892581  0.918854\n",
       "21  11000.0  0.906491   0.9032  0.881292  0.933174\n",
       "22  11500.0  0.906677   0.9044  0.890337  0.923628\n",
       "23  12000.0   0.90873    0.908  0.906572  0.910899\n",
       "24  12500.0  0.904577   0.9016  0.882665  0.927605\n",
       "25  13000.0  0.908028   0.9056  0.889992   0.92681\n",
       "26  13500.0  0.907537   0.9048  0.886864  0.929196\n",
       "27  14000.0  0.908171   0.9056  0.888804  0.928401\n",
       "28  14500.0  0.907746   0.9052   0.88872  0.927605\n",
       "29  15000.0  0.907465   0.9048  0.887452  0.928401\n",
       "30  15500.0  0.907818   0.9052  0.888128  0.928401\n",
       "31  16000.0  0.908171   0.9056  0.888804  0.928401\n",
       "32  16500.0  0.908171   0.9056  0.888804  0.928401\n",
       "33  17000.0  0.907746   0.9052   0.88872  0.927605\n",
       "34  17500.0  0.907321   0.9048  0.888635   0.92681\n",
       "35  18000.0  0.907321   0.9048  0.888635   0.92681\n",
       "36  18500.0  0.907321   0.9048  0.888635   0.92681\n",
       "37  19000.0  0.907321   0.9048  0.888635   0.92681\n",
       "38  19500.0  0.907746   0.9052   0.88872  0.927605\n",
       "39  20000.0  0.907746   0.9052   0.88872  0.927605\n",
       "40    500.0  0.907746   0.9052   0.88872  0.927605"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df # try1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b61e44-1802-4131-8c40-1981e0ae9958",
   "metadata": {},
   "source": [
    "## Prediction results with rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c930b8d-d334-40a2-bc9f-74a3d5e2abec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 625/625 [00:19<00:00, 31.61it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_best = torch.load(os.path.join(results_path, \"best_model.pth\"))\n",
    "model_best = HSRuleModel(checkpoint, num_labels=2, rule_dimension=26).to(device)\n",
    "model_best.load_state_dict(checkpoint_best['model_state_dict'])\n",
    "model.train()\n",
    "\n",
    "test_dataloader = DataLoader(dataset_dict[\"test\"], batch_size=batch_size, shuffle=False)\n",
    "all_predictions = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    rec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    prec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    all_predictions.extend(predictions.cpu().tolist())\n",
    "test_set_dict = {\n",
    "    \"Precision\": prec.compute()['precision'],\n",
    "    \"Recall\": rec.compute()['recall'],\n",
    "    \"Accuracy\": acc.compute()['accuracy'],\n",
    "    \"F1\": f1.compute()['f1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e642f8ef-9a67-4f8e-8861-ccff4e04c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.8953040800615858,\n",
       " 'Recall': 0.9266932270916335,\n",
       " 'Accuracy': 0.9086904285142171,\n",
       " 'F1': 0.9107282693813624}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict # with weighting - middle step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2839b947-629b-4468-8e41-39cd124f4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.8771535580524344,\n",
       " 'Recall': 0.9330677290836653,\n",
       " 'Accuracy': 0.9006808169803765,\n",
       " 'F1': 0.9042471042471042}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d205c69-1f00-439b-9882-80a87df666bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.8925556408288565,\n",
       " 'Recall': 0.9266932270916335,\n",
       " 'Accuracy': 0.907088506207449,\n",
       " 'F1': 0.9093041438623924}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict # big model double rule weighting drop 0.2 pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3871927-3b37-4236-a6f8-325f36cd3487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31fed763-6420-49dd-a4a1-07c9499eb7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.9059011164274322,\n",
       " 'Recall': 0.9051792828685259,\n",
       " 'Accuracy': 0.9050861033239888,\n",
       " 'F1': 0.9055400557991231}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict # big model double rule weighting pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7191677-95e5-46dd-bd7d-902082bb6ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.906885758998435,\n",
       " 'Recall': 0.9235059760956176,\n",
       " 'Accuracy': 0.9138966760112135,\n",
       " 'F1': 0.9151204105803395}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict # big model double rule best model pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64209d46-bcbf-42f9-9084-d76a40a20be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d797449-fd02-402d-bb39-71dc50aef018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.906396255850234,\n",
       " 'Recall': 0.9258964143426295,\n",
       " 'Accuracy': 0.9146976371645975,\n",
       " 'F1': 0.916042569964525}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict # big model with rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99b26fef-9ce7-4fe6-8bae-0d090fcb9c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.9091633466135458,\n",
       " 'Recall': 0.9091633466135458,\n",
       " 'Accuracy': 0.9086904285142171,\n",
       " 'F1': 0.9091633466135458}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "476a4ba5-6d97-4c56-bb47-f4b77b03a768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.88558352402746,\n",
       " 'Recall': 0.9250996015936255,\n",
       " 'Accuracy': 0.9022827392871445,\n",
       " 'F1': 0.9049103663289166}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82970dd0-b36e-4318-8cf6-f4cf72e9cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138966760112135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_rule = pd.DataFrame(data={\"id\": dataset_dict[\"test\"].idxs, \"Label\": dataset_dict[\"test\"].labels, \"pred\": all_predictions})\n",
    "df_pred_rule[\"Label\"] = df_pred_rule[\"Label\"].map(dataset_dict[\"test\"].rev_label_encodings)\n",
    "df_pred_rule[\"pred\"] = df_pred_rule[\"pred\"].map(dataset_dict[\"test\"].rev_label_encodings)\n",
    "sum(df_pred_rule[\"Label\"] == df_pred_rule[\"pred\"]) / df_pred_rule.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6cdabb7-e46f-4ea8-a2c8-c58ca5a81a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_pred_rule[\"Label\"] == df_pred_rule[\"pred\"]) - sum(df_pred_baseline[\"Label\"] == df_pred_baseline[\"pred\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff2d19d-5522-4953-b169-0d43255ad624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_baseline = pd.read_csv(\"../../data/berturk_baseline_preds_test_set.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72217daf-e682-4c9c-94b6-2b3636d3f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds = pd.merge(df_pred_rule, df_pred_baseline.drop(\"Label\", axis=1), on=\"id\", how=\"inner\", suffixes=[\"_rule\", \"_baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc96e583-afa8-4eed-b5d7-c096ee59dd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>pred_rule</th>\n",
       "      <th>pred_baseline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>134</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>suriyeli qassapa yıl türk sanıklara beraat ıı ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>442</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>ben yahudiyim dedi konu mankeni obama ben yahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>625</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>kj ta dr canay umunç yarim bırakılan hikayeler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1108</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>vatanın mı var senin mehmet akarca hürriyet ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1336</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>agah oktay güner one minute gerçeği yeni bir o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>24719</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>hakkımızı almak istiyoruz hakkımızı almak isti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>24909</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>bilinçli siyasetle terör biter mustafa miyasog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>24945</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>transseksüel eşini travestiyle aldattı transse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>24947</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>pkklıya geberdi diyelim pkkhya geberdi diyelim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>24952</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>travestiler polise enselendi travestiler polis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     Label pred_rule pred_baseline  \\\n",
       "17      134      hate      hate      not_hate   \n",
       "60      442      hate      hate      not_hate   \n",
       "78      625      hate  not_hate          hate   \n",
       "118    1108      hate      hate      not_hate   \n",
       "141    1336      hate  not_hate          hate   \n",
       "...     ...       ...       ...           ...   \n",
       "2463  24719  not_hate      hate      not_hate   \n",
       "2480  24909      hate      hate      not_hate   \n",
       "2482  24945      hate      hate      not_hate   \n",
       "2483  24947      hate      hate      not_hate   \n",
       "2484  24952      hate      hate      not_hate   \n",
       "\n",
       "                                                   text  \n",
       "17    suriyeli qassapa yıl türk sanıklara beraat ıı ...  \n",
       "60    ben yahudiyim dedi konu mankeni obama ben yahu...  \n",
       "78    kj ta dr canay umunç yarim bırakılan hikayeler...  \n",
       "118   vatanın mı var senin mehmet akarca hürriyet ah...  \n",
       "141   agah oktay güner one minute gerçeği yeni bir o...  \n",
       "...                                                 ...  \n",
       "2463  hakkımızı almak istiyoruz hakkımızı almak isti...  \n",
       "2480  bilinçli siyasetle terör biter mustafa miyasog...  \n",
       "2482  transseksüel eşini travestiyle aldattı transse...  \n",
       "2483  pkklıya geberdi diyelim pkkhya geberdi diyelim...  \n",
       "2484  travestiler polise enselendi travestiler polis...  \n",
       "\n",
       "[115 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_preds[df_all_preds[\"pred_rule\"] != df_all_preds[\"pred_baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8ba7656-9272-4531-8ea5-a4a186a6661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds.to_csv(\"../../data/berturk_baseline_and_rules_preds_test_set_big_rule_model_91389.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e447ed-75d2-4f59-8b03-1bb3123dfdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63a3660-2fb3-4807-a87c-0ca70cef546f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "list_converters = {'sentences': pd.eval, \"special_pattern\": pd.eval, \"anti_hs\": pd.eval, \"hs_specific_verb\": pd.eval, \"adj_bef_keyword\": pd.eval, \"adj_after_keyword\": pd.eval}\n",
    "ukrayna_data = pd.read_csv(\"../../data/data_cleaned_sentences_rules_ukrayna.csv\", sep='|', converters=list_converters)\n",
    "ukrayna_data[\"title\"] = ukrayna_data[\"title\"].parallel_apply(lambda title: title if isinstance(title, str) else \"\") \n",
    "ukrayna_data[\"text\"] = ukrayna_data.parallel_apply(lambda row: \" \".join([sent for sent in [row[\"title\"]] + row[\"sentences\"]]), axis=1)\n",
    "ukrayna_data[\"all_rules\"] = ukrayna_data.apply(lambda row: np.array(row[\"special_pattern\"] + [row[\"general_rule\"]] + row[\"anti_hs\"] + row[\"hs_specific_verb\"] + row[\"adj_bef_keyword\"] + row[\"adj_after_keyword\"]).astype(np.float32), axis=1)\n",
    "\n",
    "phase = \"test\"\n",
    "ukrayna_test_idxs = list(ukrayna_data.loc[ukrayna_data[\"phase\"] == phase, \"id\"].values)\n",
    "ukrayna_test_texts = list(ukrayna_data.loc[ukrayna_data[\"phase\"] == phase, \"text\"].values)\n",
    "ukrayna_test_labels = list(ukrayna_data.loc[ukrayna_data[\"phase\"] == phase, \"Label\"].values)\n",
    "ukrayna_test_all_rules = list(ukrayna_data.loc[ukrayna_data[\"phase\"] == phase, \"all_rules\"].values)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")\n",
    "ukrayna_test_encodings = tokenizer(ukrayna_test_texts, truncation=True, padding=True)\n",
    "ukrayna_test_dataset = HDVDataset(ukrayna_test_encodings, ukrayna_test_labels, ukrayna_test_idxs, ukrayna_test_all_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7996d67-3386-47f2-8001-6e5e3fc32206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 8/8 [00:00<00:00, 35.31it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_best = torch.load(os.path.join(results_path, \"best_model.pth\"))\n",
    "model_best = HSRuleModel(checkpoint, num_labels=2, rule_dimension=26).to(device)\n",
    "model_best.load_state_dict(checkpoint_best['model_state_dict'])\n",
    "model_best.eval()\n",
    "\n",
    "ukrayna_test_dataloader = DataLoader(ukrayna_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "all_predictions = []\n",
    "for batch in tqdm(ukrayna_test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_best(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    rec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    prec.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    all_predictions.extend(predictions.cpu().tolist())\n",
    "ukrayna_test_set_dict = {\n",
    "    \"Precision\": prec.compute()['precision'],\n",
    "    \"Recall\": rec.compute()['recall'],\n",
    "    \"Accuracy\": acc.compute()['accuracy'],\n",
    "    \"F1\": f1.compute()['f1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d2c1d55-5de4-4ea8-b15c-941061e35f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 1.0,\n",
       " 'Recall': 0.8666666666666667,\n",
       " 'Accuracy': 0.9333333333333333,\n",
       " 'F1': 0.9285714285714286}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukrayna_test_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fdff482-cfee-4993-b1df-ab64f0dcf127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 1.0,\n",
       " 'Recall': 0.9333333333333333,\n",
       " 'Accuracy': 0.9666666666666667,\n",
       " 'F1': 0.9655172413793104}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukrayna_test_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479c599e-3a2b-454f-95e8-422eb5a2ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "df_pred_ukrayna_rule = pd.DataFrame(data={\"id\": ukrayna_test_dataset.idxs, \"Label\": ukrayna_test_dataset.labels, \"pred\": all_predictions})\n",
    "df_pred_ukrayna_rule[\"Label\"] = df_pred_ukrayna_rule[\"Label\"].map(ukrayna_test_dataset.rev_label_encodings)\n",
    "df_pred_ukrayna_rule[\"pred\"] = df_pred_ukrayna_rule[\"pred\"].map(ukrayna_test_dataset.rev_label_encodings)\n",
    "print(sum(df_pred_ukrayna_rule[\"Label\"] == df_pred_ukrayna_rule[\"pred\"]) / df_pred_ukrayna_rule.shape[0])\n",
    "\n",
    "df_pred_ukrayna_baseline = pd.read_csv(\"../../data/berturk_baseline_preds_ukrayna_test_set.csv\", sep=\"|\")\n",
    "df_all_ukrayna_preds = pd.merge(df_pred_ukrayna_rule, df_pred_ukrayna_baseline.drop(\"Label\", axis=1), on=\"id\", how=\"inner\", suffixes=[\"_rule\", \"_baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a5d577a-5f24-4a7b-9d18-85d678205022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>pred_rule</th>\n",
       "      <th>pred_baseline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>rus işgali mutlaka durdurulmalı rus işgali mut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar barbarca saldırıyor uydu görüntüleri yü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>rus yayılmacılığı putinle hortladı rus yayılm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>harkivde rusların ilerlemesi sürüyor harkivde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar kievde ingiliz gazetecilere ateş açtı r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>ruslar ilerliyor ukrayna direniyor ruslar iler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>ruslar starokostiantyniv üssünü vurdu ruslar s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>direnme teslim ol ukrayna murat özer murat dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar çocukları hastanede esir aldı ruslar co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar abdli gazeteciyi öldürdü ruslar abdli g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar tiktok izleyip avm vurdu tiktoker tutuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>en iyi rus ölü rus en iyi rus ölü rus londranı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>rus işgaline toplu direniş rus işgaline toplu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>rus geleneği soykırım son yüzyılda sayısız soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>ruslar çıldırdı ruslar çıldırdı rusyanın ukray...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>rusyaya özel şirket ablukası dünya devleri ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>mülteci sayısı milyonu bulabilir mülteci sayis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>ankarada ukrayna için diplomasi trafiği rusya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>silahsız insanların bombalanmasını affetmeyece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>rusya dünyanın en çok yaptırım uygulanan ülkes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>ukraynadan komşu ülkere geçen mülteci sayısı m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>savaşın rakamları savaşın rakamları rusya ile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>putin sivilleri vurmakla büyük savaş suçu işli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>rus rublesinde değer kaybı sürüyor rus rublesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>kadınlar barış istedi kadınlar barış istedi ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>sivillerin tahliyesi için insani yardım korido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>kievde iki kişiden biri artık evinde değil kie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>altın ve petrolde dalgalanma sürüyor altın ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>saatlik gergin bekleyiş ctlil kievde saatlik s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>rus rapçiden istanbulda ukraynaya destek konse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     Label pred_rule pred_baseline  \\\n",
       "0    0      hate      hate          hate   \n",
       "1    1      hate      hate          hate   \n",
       "2    2      hate      hate          hate   \n",
       "3    3      hate      hate          hate   \n",
       "4    4      hate      hate          hate   \n",
       "5    5      hate      hate      not_hate   \n",
       "6    6      hate      hate      not_hate   \n",
       "7    7      hate      hate          hate   \n",
       "8    8      hate      hate          hate   \n",
       "9    9      hate      hate          hate   \n",
       "10  10      hate      hate          hate   \n",
       "11  11      hate  not_hate      not_hate   \n",
       "12  12      hate      hate          hate   \n",
       "13  13      hate      hate          hate   \n",
       "14  14      hate      hate          hate   \n",
       "15  15  not_hate  not_hate      not_hate   \n",
       "16  16  not_hate  not_hate      not_hate   \n",
       "17  17  not_hate  not_hate      not_hate   \n",
       "18  18  not_hate  not_hate      not_hate   \n",
       "19  19  not_hate  not_hate      not_hate   \n",
       "20  20  not_hate  not_hate      not_hate   \n",
       "21  21  not_hate  not_hate      not_hate   \n",
       "22  22  not_hate  not_hate      not_hate   \n",
       "23  23  not_hate  not_hate      not_hate   \n",
       "24  24  not_hate  not_hate      not_hate   \n",
       "25  25  not_hate  not_hate      not_hate   \n",
       "26  26  not_hate  not_hate      not_hate   \n",
       "27  27  not_hate  not_hate      not_hate   \n",
       "28  28  not_hate  not_hate      not_hate   \n",
       "29  29  not_hate  not_hate      not_hate   \n",
       "\n",
       "                                                 text  \n",
       "0   rus işgali mutlaka durdurulmalı rus işgali mut...  \n",
       "1   ruslar barbarca saldırıyor uydu görüntüleri yü...  \n",
       "2   rus yayılmacılığı putinle hortladı rus yayılm ...  \n",
       "3   harkivde rusların ilerlemesi sürüyor harkivde ...  \n",
       "4   ruslar kievde ingiliz gazetecilere ateş açtı r...  \n",
       "5   ruslar ilerliyor ukrayna direniyor ruslar iler...  \n",
       "6   ruslar starokostiantyniv üssünü vurdu ruslar s...  \n",
       "7   direnme teslim ol ukrayna murat özer murat dir...  \n",
       "8   ruslar çocukları hastanede esir aldı ruslar co...  \n",
       "9   ruslar abdli gazeteciyi öldürdü ruslar abdli g...  \n",
       "10  ruslar tiktok izleyip avm vurdu tiktoker tutuk...  \n",
       "11  en iyi rus ölü rus en iyi rus ölü rus londranı...  \n",
       "12  rus işgaline toplu direniş rus işgaline toplu ...  \n",
       "13  rus geleneği soykırım son yüzyılda sayısız soy...  \n",
       "14  ruslar çıldırdı ruslar çıldırdı rusyanın ukray...  \n",
       "15  rusyaya özel şirket ablukası dünya devleri ter...  \n",
       "16  mülteci sayısı milyonu bulabilir mülteci sayis...  \n",
       "17  ankarada ukrayna için diplomasi trafiği rusya ...  \n",
       "18  silahsız insanların bombalanmasını affetmeyece...  \n",
       "19  rusya dünyanın en çok yaptırım uygulanan ülkes...  \n",
       "20  ukraynadan komşu ülkere geçen mülteci sayısı m...  \n",
       "21  savaşın rakamları savaşın rakamları rusya ile ...  \n",
       "22  putin sivilleri vurmakla büyük savaş suçu işli...  \n",
       "23  rus rublesinde değer kaybı sürüyor rus rublesi...  \n",
       "24  kadınlar barış istedi kadınlar barış istedi ru...  \n",
       "25  sivillerin tahliyesi için insani yardım korido...  \n",
       "26  kievde iki kişiden biri artık evinde değil kie...  \n",
       "27  altın ve petrolde dalgalanma sürüyor altın ve ...  \n",
       "28  saatlik gergin bekleyiş ctlil kievde saatlik s...  \n",
       "29  rus rapçiden istanbulda ukraynaya destek konse...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ukrayna_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a15e390-3471-41f7-a071-afc8ed16c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_ukrayna_preds.to_csv(\"../../data/berturk_baseline_and_rules_preds_ukrayna_test_set.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a67160-6484-4432-88d8-41f3151c5c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e25128-81af-44d4-b312-aefd4f71c254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17688722-019d-4b5d-a405-da4595d74425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e32e251-04e4-4110-8082-3ce277bfdd81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fd1d23-3c14-4fcd-8668-28a3fc8b7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(results_path, \"berturk_128K_baseline\"),               # output directory\n",
    "    num_train_epochs=2,                                                  # total number of training epochs\n",
    "    per_device_train_batch_size=4,                                       # batch size per device during training\n",
    "    per_device_eval_batch_size=4,                                        # batch size for evaluation\n",
    "    warmup_steps=500,                                                    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                                                   # strength of weight decay\n",
    "    logging_dir=os.path.join(results_path, \"berturk_128K_baseline\"),              # directory for storing logs\n",
    "    logging_steps=20,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_steps=1000,\n",
    "    learning_rate=1e-05,\n",
    "    run_name=\"berturk_baseline_128K_uncased_lre-5\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                                                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                                                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,                                         # training dataset\n",
    "    eval_dataset=val_dataset,                                            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e80a4c53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arute/miniconda3/envs/nlp_env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20018\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10010\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33matifemre\u001b[0m (\u001b[33mnlpboun\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arute/Documents/nlp/doc_hatespeech_detection/notebooks/wandb/run-20220602_233632-2ywoer8z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nlpboun/hdv_hate_speech/runs/2ywoer8z\" target=\"_blank\">berturk_baseline_128K_uncased_lre-5</a></strong> to <a href=\"https://wandb.ai/nlpboun/hdv_hate_speech\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10010' max='10010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10010/10010 28:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.470783</td>\n",
       "      <td>0.764359</td>\n",
       "      <td>0.825776</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.793881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.389471</td>\n",
       "      <td>0.867442</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>0.876400</td>\n",
       "      <td>0.878681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.476330</td>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.896579</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>0.883229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.452168</td>\n",
       "      <td>0.831586</td>\n",
       "      <td>0.946698</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.445796</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.894055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.363237</td>\n",
       "      <td>0.893397</td>\n",
       "      <td>0.893397</td>\n",
       "      <td>0.892800</td>\n",
       "      <td>0.893397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>0.380949</td>\n",
       "      <td>0.860990</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.899278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.378997</td>\n",
       "      <td>0.915226</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>0.899676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>0.377014</td>\n",
       "      <td>0.870944</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.899600</td>\n",
       "      <td>0.903942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.342529</td>\n",
       "      <td>0.918219</td>\n",
       "      <td>0.902148</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.910112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.397123</td>\n",
       "      <td>0.882309</td>\n",
       "      <td>0.948290</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.914110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.364479</td>\n",
       "      <td>0.901321</td>\n",
       "      <td>0.922832</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.911950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.390794</td>\n",
       "      <td>0.912461</td>\n",
       "      <td>0.920446</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.916436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.334300</td>\n",
       "      <td>0.368901</td>\n",
       "      <td>0.891485</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.912800</td>\n",
       "      <td>0.915635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.366202</td>\n",
       "      <td>0.922393</td>\n",
       "      <td>0.907717</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>0.914996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.377915</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.922037</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>0.916206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.381383</td>\n",
       "      <td>0.907956</td>\n",
       "      <td>0.926014</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.916896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.360239</td>\n",
       "      <td>0.915739</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.916103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.375449</td>\n",
       "      <td>0.907249</td>\n",
       "      <td>0.926014</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>0.916535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.373448</td>\n",
       "      <td>0.910518</td>\n",
       "      <td>0.922832</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.916634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-1000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-1000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-2000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-2000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-3000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-3000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-4000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-4000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-5000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-5000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-6000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-6000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-7000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-7000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-8000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-8000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-9000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-9000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-10000\n",
      "Configuration saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-10000/config.json\n",
      "Model weights saved in ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-10000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../experiments_berturk_baseline/results/berturk_128K_baseline/checkpoint-5000 (score: 0.34252944588661194).\n",
      "Saving model checkpoint to /tmp/tmpzsb8xxic\n",
      "Configuration saved in /tmp/tmpzsb8xxic/config.json\n",
      "Model weights saved in /tmp/tmpzsb8xxic/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10010, training_loss=0.38251381393198247, metrics={'train_runtime': 1725.6669, 'train_samples_per_second': 23.2, 'train_steps_per_second': 5.801, 'total_flos': 1.053391421239296e+16, 'train_loss': 0.38251381393198247, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad39b6-4966-4c95-aec6-669ed22de961",
   "metadata": {},
   "source": [
    "## Evaluation (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3110b46c-0a69-4358-9ddf-380376b94000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1258' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34252944588661194,\n",
       " 'eval_precision': 0.9182186234817814,\n",
       " 'eval_recall': 0.9021479713603818,\n",
       " 'eval_accuracy': 0.9104,\n",
       " 'eval_f1': 0.9101123595505618,\n",
       " 'eval_runtime': 21.9222,\n",
       " 'eval_samples_per_second': 114.04,\n",
       " 'eval_steps_per_second': 28.51,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(val_dataset)\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8703b-9124-4c17-b393-218a9faa0524",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8421fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2497\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [0 1 1 ... 1 1 1]\n",
      " GT's: [1 1 1 ... 1 1 1]\n",
      "{'test_loss': 0.39748504757881165, 'test_precision': 0.9060240963855422, 'test_recall': 0.8988047808764941, 'test_accuracy': 0.9022827392871445, 'test_f1': 0.9024, 'test_runtime': 22.2395, 'test_samples_per_second': 112.278, 'test_steps_per_second': 28.103}\n"
     ]
    }
   ],
   "source": [
    "preds_dict = trainer.predict(test_dataset)\n",
    "predictions = preds_dict.predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(f\"Preds: {predictions}\\n GT's: {preds_dict.label_ids}\")\n",
    "print(preds_dict.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3772becc-c927-4c05-a639-0a56d01c9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>pub_name</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Label</th>\n",
       "      <th>sentences</th>\n",
       "      <th>text</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>05 Ekim 2015 Pazartesi</td>\n",
       "      <td>akşam</td>\n",
       "      <td>ulusal</td>\n",
       "      <td>sahte polislerin kuryesi yakalandı</td>\n",
       "      <td>sahte polislerin kuryesi yakalandı antalya'da ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[sahte polislerin kuryesi yakalandı antalyada ...</td>\n",
       "      <td>sahte polislerin kuryesi yakalandı sahte polis...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11 Eylül 2015 Cuma</td>\n",
       "      <td>akşam</td>\n",
       "      <td>ulusal</td>\n",
       "      <td>kürt üz ama hain değiliz</td>\n",
       "      <td>kürt'üz ama hain değiliz suriye sınırında devr...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[kürtüz ama hain değiliz suriye sınırında devr...</td>\n",
       "      <td>kürt üz ama hain değiliz kürtüz ama hain değil...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25 Eylül 2015 Cuma</td>\n",
       "      <td>akşam</td>\n",
       "      <td>ulusal</td>\n",
       "      <td>suriyeli gelinden altın vurgunu</td>\n",
       "      <td>kuyumcuda altın alırken fotoğraf çektirdi. sur...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[kuyumcuda altın alırken fotoğraf çektirdi, su...</td>\n",
       "      <td>suriyeli gelinden altın vurgunu kuyumcuda altı...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>07 Eylül 2015 Pazartesi</td>\n",
       "      <td>anayurt</td>\n",
       "      <td>ulusal</td>\n",
       "      <td>mustafa nevruz sınacı</td>\n",
       "      <td>mustafa nevruz sınacı lgercek. abd'li yahudi, ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[mustafa nevruz sınacı lgercek, abdli yahudi b...</td>\n",
       "      <td>mustafa nevruz sınacı mustafa nevruz sınacı lg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21 Eylül 2015 Pazartesi</td>\n",
       "      <td>anayurt</td>\n",
       "      <td>ulusal</td>\n",
       "      <td>mustafa nevruz sınacı</td>\n",
       "      <td>mustafa nevruz sınacı yazıyor, gercek. abd'li ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[mustafa nevruz sınacı yazıyor gercek, abdli y...</td>\n",
       "      <td>mustafa nevruz sınacı mustafa nevruz sınacı ya...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>25061</td>\n",
       "      <td>02 Mayıs 2014 Cuma</td>\n",
       "      <td>yeni asya</td>\n",
       "      <td>hepsi</td>\n",
       "      <td>amnesty ınternational ve global ahlaksızlık</td>\n",
       "      <td>doğu veya batı s. bulut@saidnursi. de amnesty ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[doğu veya batı, de amnesty ınternational ve g...</td>\n",
       "      <td>amnesty ınternational ve global ahlaksızlık do...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>25062</td>\n",
       "      <td>26 Mart 2014 Çarşamba</td>\n",
       "      <td>yeni konya</td>\n",
       "      <td>hepsi</td>\n",
       "      <td>çanakkale asla unutulmamalı llnutturulmamalı</td>\n",
       "      <td>çanakkale, asla unutulmamalı, llnutturulmamalı...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[çanakkale asla unutulmamalı llnutturulmamalı ...</td>\n",
       "      <td>çanakkale asla unutulmamalı llnutturulmamalı ç...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>25063</td>\n",
       "      <td>04 Nisan 2014 Cuma</td>\n",
       "      <td>yeni mesaj</td>\n",
       "      <td>hepsi</td>\n",
       "      <td>sömürü projesi olarak bop</td>\n",
       "      <td>btp genel başkanı prof. dr. haydar bas ın kale...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[btp genel başkanı prof, haydar bas ın kalemin...</td>\n",
       "      <td>sömürü projesi olarak bop btp genel başkanı pr...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>25064</td>\n",
       "      <td>24 Şubat 2014 Pazartesi</td>\n",
       "      <td>yeni mesaj</td>\n",
       "      <td>hepsi</td>\n",
       "      <td>doğruluş zeminimiz helali bir millet istiklali...</td>\n",
       "      <td>prof. dr. nurullah çetin doğruluş zeminimiz: '...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[nurullah çetin doğruluş zeminimiz helali bir ...</td>\n",
       "      <td>doğruluş zeminimiz helali bir millet istiklali...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25014</th>\n",
       "      <td>25065</td>\n",
       "      <td>17 Ocak 2014 Cuma</td>\n",
       "      <td>çorum hakimiyet</td>\n",
       "      <td>hepsi</td>\n",
       "      <td>yahudilikten islama yönelen bir sahabi abdulla...</td>\n",
       "      <td>yahudilikten islam'a yönelen bir sahabi abdull...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[yahudilikten islama yönelen bir sahabi abdull...</td>\n",
       "      <td>yahudilikten islama yönelen bir sahabi abdulla...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25015 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     date         pub_name    type  \\\n",
       "0          0   05 Ekim 2015 Pazartesi            akşam  ulusal   \n",
       "1          1       11 Eylül 2015 Cuma            akşam  ulusal   \n",
       "2          2       25 Eylül 2015 Cuma            akşam  ulusal   \n",
       "3          3  07 Eylül 2015 Pazartesi          anayurt  ulusal   \n",
       "4          4  21 Eylül 2015 Pazartesi          anayurt  ulusal   \n",
       "...      ...                      ...              ...     ...   \n",
       "25010  25061       02 Mayıs 2014 Cuma        yeni asya   hepsi   \n",
       "25011  25062    26 Mart 2014 Çarşamba       yeni konya   hepsi   \n",
       "25012  25063       04 Nisan 2014 Cuma       yeni mesaj   hepsi   \n",
       "25013  25064  24 Şubat 2014 Pazartesi       yeni mesaj   hepsi   \n",
       "25014  25065        17 Ocak 2014 Cuma  çorum hakimiyet   hepsi   \n",
       "\n",
       "                                                   title  \\\n",
       "0                     sahte polislerin kuryesi yakalandı   \n",
       "1                               kürt üz ama hain değiliz   \n",
       "2                        suriyeli gelinden altın vurgunu   \n",
       "3                                  mustafa nevruz sınacı   \n",
       "4                                  mustafa nevruz sınacı   \n",
       "...                                                  ...   \n",
       "25010        amnesty ınternational ve global ahlaksızlık   \n",
       "25011       çanakkale asla unutulmamalı llnutturulmamalı   \n",
       "25012                          sömürü projesi olarak bop   \n",
       "25013  doğruluş zeminimiz helali bir millet istiklali...   \n",
       "25014  yahudilikten islama yönelen bir sahabi abdulla...   \n",
       "\n",
       "                                                 content Label  \\\n",
       "0      sahte polislerin kuryesi yakalandı antalya'da ...  hate   \n",
       "1      kürt'üz ama hain değiliz suriye sınırında devr...  hate   \n",
       "2      kuyumcuda altın alırken fotoğraf çektirdi. sur...  hate   \n",
       "3      mustafa nevruz sınacı lgercek. abd'li yahudi, ...  hate   \n",
       "4      mustafa nevruz sınacı yazıyor, gercek. abd'li ...  hate   \n",
       "...                                                  ...   ...   \n",
       "25010  doğu veya batı s. bulut@saidnursi. de amnesty ...  hate   \n",
       "25011  çanakkale, asla unutulmamalı, llnutturulmamalı...  hate   \n",
       "25012  btp genel başkanı prof. dr. haydar bas ın kale...  hate   \n",
       "25013  prof. dr. nurullah çetin doğruluş zeminimiz: '...  hate   \n",
       "25014  yahudilikten islam'a yönelen bir sahabi abdull...  hate   \n",
       "\n",
       "                                               sentences  \\\n",
       "0      [sahte polislerin kuryesi yakalandı antalyada ...   \n",
       "1      [kürtüz ama hain değiliz suriye sınırında devr...   \n",
       "2      [kuyumcuda altın alırken fotoğraf çektirdi, su...   \n",
       "3      [mustafa nevruz sınacı lgercek, abdli yahudi b...   \n",
       "4      [mustafa nevruz sınacı yazıyor gercek, abdli y...   \n",
       "...                                                  ...   \n",
       "25010  [doğu veya batı, de amnesty ınternational ve g...   \n",
       "25011  [çanakkale asla unutulmamalı llnutturulmamalı ...   \n",
       "25012  [btp genel başkanı prof, haydar bas ın kalemin...   \n",
       "25013  [nurullah çetin doğruluş zeminimiz helali bir ...   \n",
       "25014  [yahudilikten islama yönelen bir sahabi abdull...   \n",
       "\n",
       "                                                    text  phase  \n",
       "0      sahte polislerin kuryesi yakalandı sahte polis...  train  \n",
       "1      kürt üz ama hain değiliz kürtüz ama hain değil...   test  \n",
       "2      suriyeli gelinden altın vurgunu kuyumcuda altı...   test  \n",
       "3      mustafa nevruz sınacı mustafa nevruz sınacı lg...  train  \n",
       "4      mustafa nevruz sınacı mustafa nevruz sınacı ya...  train  \n",
       "...                                                  ...    ...  \n",
       "25010  amnesty ınternational ve global ahlaksızlık do...  train  \n",
       "25011  çanakkale asla unutulmamalı llnutturulmamalı ç...    val  \n",
       "25012  sömürü projesi olarak bop btp genel başkanı pr...  train  \n",
       "25013  doğruluş zeminimiz helali bir millet istiklali...  train  \n",
       "25014  yahudilikten islama yönelen bir sahabi abdulla...  train  \n",
       "\n",
       "[25015 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51759774-2895-4370-b748-56c80b291955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>pred</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>kürt üz ama hain değiliz kürtüz ama hain değil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>suriyeli gelinden altın vurgunu kuyumcuda altı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sabahattin önkibar daha politika günlüğü sabah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>kafkasya nın bitmeyen sorunu yukarı karabağ ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sözde kürt özde kripto ermeni sözde kürt özde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>25018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>elin gavuru kadar olamayan islamcılar elin gav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>25035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>müslümanları katleden haçlı zihniyetinin noel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>25044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sen sağ ben selamet sen yoluna ben yoluma it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>25049</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yahudinin bir ayağı türkiyede yahudinin bir ay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>25060</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yahudiler gibi oldu önem cemaatin üst kademele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Label  pred                                               text\n",
       "0         1      1     0  kürt üz ama hain değiliz kürtüz ama hain değil...\n",
       "1         2      1     1  suriyeli gelinden altın vurgunu kuyumcuda altı...\n",
       "2        11      1     1  sabahattin önkibar daha politika günlüğü sabah...\n",
       "3        15      1     1  kafkasya nın bitmeyen sorunu yukarı karabağ ce...\n",
       "4        26      1     1  sözde kürt özde kripto ermeni sözde kürt özde ...\n",
       "...     ...    ...   ...                                                ...\n",
       "2492  25018      1     1  elin gavuru kadar olamayan islamcılar elin gav...\n",
       "2493  25035      1     1  müslümanları katleden haçlı zihniyetinin noel ...\n",
       "2494  25044      1     1  sen sağ ben selamet sen yoluna ben yoluma it s...\n",
       "2495  25049      1     1  yahudinin bir ayağı türkiyede yahudinin bir ay...\n",
       "2496  25060      1     1  yahudiler gibi oldu önem cemaatin üst kademele...\n",
       "\n",
       "[2497 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(data={\"id\": test_dataset.idxs, \"Label\": test_dataset.labels, \"pred\": predictions})\n",
    "df_pred = pd.merge(df_pred, data[[\"id\", \"text\"]], how=\"left\", on=\"id\")\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5797528-e4bf-4c93-b603-af1d9ebccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"../../data/berturk_baseline_preds_test_set.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e098b28a-72be-4a5a-936e-d02d2c3cd743",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "ukrayna_data = pd.read_csv(\"../../data/data_cleaned_sentences_ukrayna.csv\", sep='|', converters={'sentences': pd.eval})\n",
    "ukrayna_data[\"title\"] = ukrayna_data[\"title\"].parallel_apply(lambda title: title if isinstance(title, str) else \"\") \n",
    "ukrayna_data[\"text\"] = ukrayna_data.parallel_apply(lambda row: \" \".join([sent for sent in [row[\"title\"]] + row[\"sentences\"]]), axis=1)\n",
    "\n",
    "ukrayna_test_idxs, ukrayna_test_texts, ukrayna_test_labels = list(ukrayna_data.loc[ukrayna_data[\"phase\"] == \"test\", \"id\"].values), list(ukrayna_data.loc[ukrayna_data[\"phase\"] == \"test\", \"text\"].values), list(ukrayna_data.loc[ukrayna_data[\"phase\"] == \"test\", \"Label\"].values)\n",
    "ukrayna_test_encodings = tokenizer(ukrayna_test_texts, truncation=True, padding=True)\n",
    "ukrayna_test_dataset = HDVDataset(ukrayna_test_encodings, ukrayna_test_labels, ukrayna_test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bb755c7-5f19-495d-b518-9d39e7aad4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 30\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " GT's: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{'test_loss': 0.37824195623397827, 'test_precision': 1.0, 'test_recall': 0.8, 'test_accuracy': 0.9, 'test_f1': 0.888888888888889, 'test_runtime': 0.2473, 'test_samples_per_second': 121.297, 'test_steps_per_second': 32.346}\n"
     ]
    }
   ],
   "source": [
    "ukrayna_preds_dict = trainer.predict(ukrayna_test_dataset)\n",
    "ukrayna_predictions = ukrayna_preds_dict.predictions\n",
    "ukrayna_predictions = np.argmax(ukrayna_predictions, axis=1)\n",
    "print(f\"Preds: {ukrayna_predictions}\\n GT's: {ukrayna_preds_dict.label_ids}\")\n",
    "print(ukrayna_preds_dict.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c07c9895-2d41-42e9-aac6-188378a15ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>pred</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rus işgali mutlaka durdurulmalı rus işgali mut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar barbarca saldırıyor uydu görüntüleri yü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rus yayılmacılığı putinle hortladı rus yayılm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>harkivde rusların ilerlemesi sürüyor harkivde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar kievde ingiliz gazetecilere ateş açtı r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ruslar ilerliyor ukrayna direniyor ruslar iler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ruslar starokostiantyniv üssünü vurdu ruslar s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>direnme teslim ol ukrayna murat özer murat dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar çocukları hastanede esir aldı ruslar co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar abdli gazeteciyi öldürdü ruslar abdli g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar tiktok izleyip avm vurdu tiktoker tutuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en iyi rus ölü rus en iyi rus ölü rus londranı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rus işgaline toplu direniş rus işgaline toplu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rus geleneği soykırım son yüzyılda sayısız soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ruslar çıldırdı ruslar çıldırdı rusyanın ukray...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rusyaya özel şirket ablukası dünya devleri ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mülteci sayısı milyonu bulabilir mülteci sayis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ankarada ukrayna için diplomasi trafiği rusya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>silahsız insanların bombalanmasını affetmeyece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rusya dünyanın en çok yaptırım uygulanan ülkes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ukraynadan komşu ülkere geçen mülteci sayısı m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>savaşın rakamları savaşın rakamları rusya ile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>putin sivilleri vurmakla büyük savaş suçu işli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rus rublesinde değer kaybı sürüyor rus rublesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kadınlar barış istedi kadınlar barış istedi ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sivillerin tahliyesi için insani yardım korido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kievde iki kişiden biri artık evinde değil kie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>altın ve petrolde dalgalanma sürüyor altın ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>saatlik gergin bekleyiş ctlil kievde saatlik s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rus rapçiden istanbulda ukraynaya destek konse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Label  pred                                               text\n",
       "0    0      1     1  rus işgali mutlaka durdurulmalı rus işgali mut...\n",
       "1    1      1     1  ruslar barbarca saldırıyor uydu görüntüleri yü...\n",
       "2    2      1     1  rus yayılmacılığı putinle hortladı rus yayılm ...\n",
       "3    3      1     1  harkivde rusların ilerlemesi sürüyor harkivde ...\n",
       "4    4      1     1  ruslar kievde ingiliz gazetecilere ateş açtı r...\n",
       "5    5      1     0  ruslar ilerliyor ukrayna direniyor ruslar iler...\n",
       "6    6      1     0  ruslar starokostiantyniv üssünü vurdu ruslar s...\n",
       "7    7      1     1  direnme teslim ol ukrayna murat özer murat dir...\n",
       "8    8      1     1  ruslar çocukları hastanede esir aldı ruslar co...\n",
       "9    9      1     1  ruslar abdli gazeteciyi öldürdü ruslar abdli g...\n",
       "10  10      1     1  ruslar tiktok izleyip avm vurdu tiktoker tutuk...\n",
       "11  11      1     0  en iyi rus ölü rus en iyi rus ölü rus londranı...\n",
       "12  12      1     1  rus işgaline toplu direniş rus işgaline toplu ...\n",
       "13  13      1     1  rus geleneği soykırım son yüzyılda sayısız soy...\n",
       "14  14      1     1  ruslar çıldırdı ruslar çıldırdı rusyanın ukray...\n",
       "15  15      0     0  rusyaya özel şirket ablukası dünya devleri ter...\n",
       "16  16      0     0  mülteci sayısı milyonu bulabilir mülteci sayis...\n",
       "17  17      0     0  ankarada ukrayna için diplomasi trafiği rusya ...\n",
       "18  18      0     0  silahsız insanların bombalanmasını affetmeyece...\n",
       "19  19      0     0  rusya dünyanın en çok yaptırım uygulanan ülkes...\n",
       "20  20      0     0  ukraynadan komşu ülkere geçen mülteci sayısı m...\n",
       "21  21      0     0  savaşın rakamları savaşın rakamları rusya ile ...\n",
       "22  22      0     0  putin sivilleri vurmakla büyük savaş suçu işli...\n",
       "23  23      0     0  rus rublesinde değer kaybı sürüyor rus rublesi...\n",
       "24  24      0     0  kadınlar barış istedi kadınlar barış istedi ru...\n",
       "25  25      0     0  sivillerin tahliyesi için insani yardım korido...\n",
       "26  26      0     0  kievde iki kişiden biri artık evinde değil kie...\n",
       "27  27      0     0  altın ve petrolde dalgalanma sürüyor altın ve ...\n",
       "28  28      0     0  saatlik gergin bekleyiş ctlil kievde saatlik s...\n",
       "29  29      0     0  rus rapçiden istanbulda ukraynaya destek konse..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_ukrayna = pd.DataFrame(data={\"id\": ukrayna_test_dataset.idxs, \"Label\": ukrayna_test_dataset.labels, \"pred\": ukrayna_predictions})\n",
    "df_pred_ukrayna = pd.merge(df_pred_ukrayna, ukrayna_data[[\"id\", \"text\"]], how=\"left\", on=\"id\")\n",
    "df_pred_ukrayna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f75b9e3-ebf3-486e-b6b3-ceabc9840613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_ukrayna.to_csv(\"../../data/berturk_baseline_preds_ukrayna_test_set.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb935f4-6f3b-4acc-81f6-2e5225bf9e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b818d-0661-4135-8fdf-2cdc2bc86d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20e05409-016d-43bb-b5cc-ad44ec3cace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDVDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts_idxs, labels, tokenizer):\n",
    "        self.label_encodings = {\"not_hate\": 0, \"hate\": 1}\n",
    "        self.rev_label_encodings = {0: \"not_hate\", 1: \"hate\"}\n",
    "        \n",
    "        self.texts, self.idxs = list(np.array(texts_idxs)[:, 0]), list(np.array(texts_idxs)[:, 1])\n",
    "        self.encodings = tokenizer(self.texts, truncation=True, padding=True)\n",
    "        self.labels = [self.label_encodings[label] for label in labels]\n",
    "        self.preds = []\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def _get_preds_with_idx(self):\n",
    "        df_preds = pd.DataFrame(data={\"idx\": self.idxs, \"prediction\": self.preds})\n",
    "        df_preds[\"prediction\"] = df_preds[\"prediction\"].map(self.rev_label_encodings)\n",
    "        return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b33ce1fa-1894-4280-8ce7-960e0da33ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_idxs, labels = list(data[[\"text\", \"id\"]].values), list(data[\"Label\"].values)\n",
    "train_texts_idxs_2, val_texts_idxs_2, train_labels_2, val_labels_2 = train_test_split(texts_idxs, labels, stratify=labels, test_size=.2, shuffle=True, random_state=17)\n",
    "val_texts_idxs_2, test_texts_idxs_2, val_labels_2, test_labels_2 = train_test_split(val_texts_idxs_2, val_labels_2, stratify=val_labels_2, test_size=.5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f944246f-86a6-4010-966d-08e99938b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_idx = HDVDatasetTest(test_texts_idxs_2, test_labels_2, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa51f1-9524-47db-8249-b6d24dddccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aa375aa-f4f4-4478-9b29-f0f4e68c527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2507\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [1 0 1 ... 1 0 1]\n",
      " GT's: [1 0 1 ... 1 0 1]\n",
      "{'test_loss': 0.42105528712272644, 'test_precision': 0.8891419893697798, 'test_recall': 0.9271575613618369, 'test_accuracy': 0.9050658157159952, 'test_f1': 0.9077519379844963, 'test_runtime': 23.0777, 'test_samples_per_second': 108.633, 'test_steps_per_second': 27.169}\n"
     ]
    }
   ],
   "source": [
    "preds_dict = trainer.predict(test_dataset)\n",
    "predictions = preds_dict.predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(f\"Preds: {predictions}\\n GT's: {preds_dict.label_ids}\")\n",
    "print(preds_dict.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "209c979d-16db-49e2-b5fa-97f4e345ca5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37011e44-0fdd-492e-9ad8-0ca38221b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2507\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [1 0 1 ... 1 0 1]\n",
      " GT's: [1 0 1 ... 1 0 1]\n",
      "{'test_loss': 0.42105528712272644, 'test_precision': 0.8891419893697798, 'test_recall': 0.9271575613618369, 'test_accuracy': 0.9050658157159952, 'test_f1': 0.9077519379844963, 'test_runtime': 23.2055, 'test_samples_per_second': 108.035, 'test_steps_per_second': 27.019}\n"
     ]
    }
   ],
   "source": [
    "preds_dict_2 = trainer.predict(test_dataset_idx)\n",
    "predictions_2 = preds_dict_2.predictions\n",
    "predictions_2 = np.argmax(predictions_2, axis=1)\n",
    "print(f\"Preds: {predictions_2}\\n GT's: {preds_dict_2.label_ids}\")\n",
    "print(preds_dict_2.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2585239a-7278-4a05-ad6d-5c79efe0fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_idx.preds = predictions_2\n",
    "df_preds = test_dataset_idx._get_preds_with_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d82d23b7-f456-4230-b3cd-79d07986bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3973</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16849</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9186</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3072</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10346</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>3672</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>18446</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>3657</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>19535</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>8945</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx prediction\n",
       "0      3973       hate\n",
       "1     16849   not_hate\n",
       "2      9186       hate\n",
       "3      3072       hate\n",
       "4     10346       hate\n",
       "...     ...        ...\n",
       "2502   3672       hate\n",
       "2503  18446   not_hate\n",
       "2504   3657       hate\n",
       "2505  19535   not_hate\n",
       "2506   8945       hate\n",
       "\n",
       "[2507 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab619e57-c533-480e-bc2a-c32d0f174665",
   "metadata": {},
   "source": [
    "## Report to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbd5a102-9b0d-45be-9335-3fa46f999bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_preds = pd.merge(data, df_preds, left_on=\"id\", right_on=\"idx\", how=\"right\").drop(\"idx\", axis=1)\n",
    "df_label_preds.to_excel(\"../outputs/labels_preds_berturk_2022-04-14.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce0d0553-4d65-455f-bd9a-41a2c41b013a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3973</td>\n",
       "      <td>haber seyfullah koyuncu freddy mercurynin aske...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16849</td>\n",
       "      <td>kilisede hz fatıma nın doğumu kutlandı kilised...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9186</td>\n",
       "      <td>yunanlıların verdiği zararları anlatan resmi d...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3072</td>\n",
       "      <td>itı hr it serdar çalışkan yaptığı açıklamada ş...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10346</td>\n",
       "      <td>mültecileri dövüp geri gönderdiler mültecileri...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>3672</td>\n",
       "      <td>saitiyor su rl yıu ur bpfjmkmmiami rj fiil il ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>18446</td>\n",
       "      <td>bu işbirllfii türkiye ye örnek oucak bu işbirl...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>3657</td>\n",
       "      <td>mersinde işlenen cinayetle ilgili suriyeli tut...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>19535</td>\n",
       "      <td>siparişle kurulan proje örgütlerdir siparişle ...</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>not_hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>8945</td>\n",
       "      <td>içimizi içimizi döktüğümüz duvarlar handan yal...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text     Label  \\\n",
       "0      3973  haber seyfullah koyuncu freddy mercurynin aske...      hate   \n",
       "1     16849  kilisede hz fatıma nın doğumu kutlandı kilised...  not_hate   \n",
       "2      9186  yunanlıların verdiği zararları anlatan resmi d...      hate   \n",
       "3      3072  itı hr it serdar çalışkan yaptığı açıklamada ş...      hate   \n",
       "4     10346  mültecileri dövüp geri gönderdiler mültecileri...      hate   \n",
       "...     ...                                                ...       ...   \n",
       "2502   3672  saitiyor su rl yıu ur bpfjmkmmiami rj fiil il ...      hate   \n",
       "2503  18446  bu işbirllfii türkiye ye örnek oucak bu işbirl...  not_hate   \n",
       "2504   3657  mersinde işlenen cinayetle ilgili suriyeli tut...      hate   \n",
       "2505  19535  siparişle kurulan proje örgütlerdir siparişle ...  not_hate   \n",
       "2506   8945  içimizi içimizi döktüğümüz duvarlar handan yal...      hate   \n",
       "\n",
       "     prediction  \n",
       "0          hate  \n",
       "1      not_hate  \n",
       "2          hate  \n",
       "3          hate  \n",
       "4          hate  \n",
       "...         ...  \n",
       "2502       hate  \n",
       "2503   not_hate  \n",
       "2504       hate  \n",
       "2505   not_hate  \n",
       "2506       hate  \n",
       "\n",
       "[2507 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a81a4df-ebec-4a0c-b12e-dee52fdd9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../data/data_cleaned_sentences_2020-04-10.csv\", sep='|', converters={'sentences': pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ec565bc-ab4f-4756-ab2e-4d78bc1bb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_raw.reset_index().rename(columns={\"index\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c3c1a31-0846-4d15-9eb9-e902eeae20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_and_preds = pd.merge(data_raw, df_preds, left_on=\"id\", right_on=\"idx\", how=\"right\").drop(\"idx\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d26d628d-4c80-4ce2-87d3-e531957336a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_and_preds.to_excel(\"../outputs/data_and_preds_2022-04-14.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e89c12-ec6d-4715-af9b-f77f0db75658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050658157159952"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_data_and_preds[\"Label\"] == df_data_and_preds[\"prediction\"]) / df_data_and_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4ff115a-25c0-41cd-9a99-9eb2b5c187c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hate': 1264, 'not_hate': 1243})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828fbda-52e1-47aa-a037-495319d60750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea187edb-7a5d-4522-ada6-506674386429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../outputs/data_and_preds_2022-04-14.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0036d72-5356-426b-b367-3a6202140069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046856227472968"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(df[\"Label\"] == df[\"prediction\"]) - len(remove_id_from_test)) / (df.shape[0] - len(remove_id_from_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d46c4-323b-4151-b093-920fc9a7609f",
   "metadata": {},
   "source": [
    "## Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "291e06b8-5b3a-4d4c-be19-8c0a104972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_excel = pd.read_excel(\"../outputs/data_and_preds_2022-04-14.xlsx\")[\"id\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16084c1-14aa-4787-b137-3fcffd686f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.array(test_texts_idxs_2)[:, 1]) == id_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5234732-8ef7-4d34-9041-564f3570a220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.intersection(set(np.array(test_texts_idxs_2)[:, 1]), set(np.array(train_texts_idxs_2)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f10f8-ebdf-47a0-b5c3-2eef44886513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8eafbcf3-f78e-430a-abaf-bced5e0f70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pair = data[data[[\"text\"]].duplicated(keep=\"first\")].sort_values(\"text\").id.values.tolist()\n",
    "last_pair = data[data[[\"text\"]].duplicated(keep=\"last\")].sort_values(\"text\").id.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7831696a-0bd6-477a-998a-43b6d53b193a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [[first_pair[i], last_pair[i]] for i in range(len(first_pair))]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99e7e8fc-a3b0-4d8d-9078-33117af2fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, val_idxs, test_idxs = list(np.array(train_texts_idxs_2)[:, 1]), list(np.array(val_texts_idxs_2)[:, 1]), list(np.array(test_texts_idxs_2)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22b1a03d-ff28-4c96-ae68-eb46c7a7de37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_duplicate_rows(train_idxs, test_idxs, pairs):\n",
    "    remove_id_from_test = []\n",
    "    for pair in pairs:\n",
    "        if pair[0] in train_idxs and pair[1] in train_idxs:\n",
    "            print(pair, \" is all in train set!\")\n",
    "        elif pair[0] in train_idxs and pair[1] in test_idxs:\n",
    "            print(f\"{pair[0]} in train, {pair[1]} in test, please delete from test!!!\")\n",
    "            remove_id_from_test.append(pair[1])\n",
    "        elif pair[1] in train_idxs and pair[0] in test_idxs:\n",
    "            print(f\"{pair[1]} in train, {pair[0]} in test, please delete from test!!!\")\n",
    "            remove_id_from_test.append(pair[0])\n",
    "        elif pair[0] in test_idxs and pair[1] in test_idxs:\n",
    "            print(f\"{pair[0]} in test, {pair[1]} in test, please delete one of them from test!!!\")\n",
    "            remove_id_from_test.append(pair[1])\n",
    "    remove_test_indices = []\n",
    "    for remove_id in remove_id_from_test:\n",
    "        remove_test_indices.append(test_idxs.index(remove_id))\n",
    "    remove_test_indices\n",
    "    return remove_id_from_test, remove_test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e138719f-89c6-47e0-9b25-9d34c9c61493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_id_from_test = detect_duplicate_rows(train_idxs, test_idxs, pairs)\n",
    "remove_id_from_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4ab89b3-c3ad-412b-bedf-d5b497cb6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_id_from_val = detect_duplicate_rows(train_idxs, val_idxs, pairs)\n",
    "remove_id_from_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fd6ab-6007-43db-8423-10ac8af732fe",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa3e05c3-543c-439c-b544-ac099672bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../experiments/results/berturk_128K/checkpoint-10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52c3c2d3-765e-4610-98df-7f4683585bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDVDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts_idxs, labels, tokenizer, remove_idxs):\n",
    "        self.label_encodings = {\"not_hate\": 0, \"hate\": 1}\n",
    "        self.rev_label_encodings = {0: \"not_hate\", 1: \"hate\"}\n",
    "        \n",
    "        self.texts, self.idxs = list(np.array(texts_idxs)[:, 0]), list(np.array(texts_idxs)[:, 1])\n",
    "        print(len(self.idxs))\n",
    "        self.texts = [text for i, text in enumerate(self.texts) if i not in remove_idxs]\n",
    "        self.idxs = [idx for i, idx in enumerate(self.idxs) if i not in remove_idxs]\n",
    "        self.encodings = tokenizer(self.texts, truncation=True, padding=True)\n",
    "        self.labels = [self.label_encodings[label] for i, label in enumerate(labels) if i not in remove_idxs]\n",
    "        self.preds = []\n",
    "        print(len(self.idxs))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def _get_preds_with_idx(self):\n",
    "        df_preds = pd.DataFrame(data={\"idx\": self.idxs, \"prediction\": self.preds})\n",
    "        df_preds[\"prediction\"] = df_preds[\"prediction\"].map(self.rev_label_encodings)\n",
    "        return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3df4d9c6-04e3-430f-9b02-a2e6c5e21349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507\n",
      "2497\n"
     ]
    }
   ],
   "source": [
    "test_dataset_idx_cleaned = HDVDatasetTest(test_texts_idxs_2, test_labels_2, tokenizer, remove_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e4c2db2-0a4a-4865-9981-fc789fcb3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                                                         # the instantiated 🤗 Transformers model to be trained\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "542b9347-3921-44e9-8cab-ed99cb243699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2497\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [1 0 1 ... 1 0 1]\n",
      " GT's: [1 0 1 ... 1 0 1]\n",
      "{'test_loss': 0.4224632978439331, 'test_precision': 0.8884644766997708, 'test_recall': 0.9266932270916335, 'test_accuracy': 0.9046856227472968, 'test_f1': 0.9071762870514819, 'test_runtime': 17.3161, 'test_samples_per_second': 144.201, 'test_steps_per_second': 18.076}\n"
     ]
    }
   ],
   "source": [
    "preds_dict_3 = trainer.predict(test_dataset_idx_cleaned)\n",
    "predictions_3 = preds_dict_3.predictions\n",
    "predictions_3 = np.argmax(predictions_3, axis=1)\n",
    "print(f\"Preds: {predictions_3}\\n GT's: {preds_dict_3.label_ids}\")\n",
    "print(preds_dict_3.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf03f58-29f3-4fd2-9000-a3b62809d059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP Env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
